# GettingAndCleaningData_W4_PGA
Week 4 Programming Assignment for 'Getting and Cleaning Data'

## Overview
In this assignment, we demonstrate a data tidying project based on the human actitivy data set from http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones

For this purpose, the script `run_analysis.R` has been created, which does the following:
1. Merges the training and the test sets to create one data set.
2. Extracts only the measurements on the mean and standard deviation for each measurement.
3. Uses descriptive activity names to name the activities in the data set
4. Appropriately labels the data set with descriptive variable names.
5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
6. The simplified output is saved in the file `tidy_wearables_summary.csv`

## Methodology
1. The files x_test.txt fortunately have only one observation per line, but the independent variables (activity and subject) are in separte files. As a first step, the three files are column wise appended into one data table
2. I am using data tables instead of data frames because the grammar for subsetting is more readable and performance is supposed to be faster
3. 'Test' and 'Train' data are in separate folders. Once the data tables are read in for each, they are joined to form one data table using `rbind`.
4. Only the columns of interest (mean and standard deviation) are extracted using the `select()` grammar and pattern matching; care has been taken so that names that have 'mean' in them but are not means (e.g., gravitymean, freqmean) are not selected
5. The activity id is denormalized by to use category variable with names for the activity (walking, laying, etc.)
6. Subjective judgement has been used to make the column names readable. The methodology is encoded in the functions in the file `clean_label.R`. The steps are as follows:
    1. Remove cryptic prefix 'f' and 't' and use 'freq domain' and 'time domain' instead
    2. Chnage camel case and separate by underscores, e.g. tBodyAcc-iqr  becomes time_domain_body_acc_iqr
    3. Change all variables to lower case
    4. Remove empty parantheses, e.g., tBodyAcc-iqr()-X becomes time_domain_body_acc_iqr_x
    5. Fix columns 516 to 554 where we have 'BodyBody' instead of 'Body'
    6. Remove extra ")" in column 556 (not implemented)
    7. Change spaces and hyphens to underscores
    8. Make column names unique: There are three sets of repeated column names, in each of these sets, the column name (e.g., fBodyGyro-bandsEnergy()) is repeated three times: once each for x, y, and z values. Add the suffix x, y, and Z to make the column names unique

## Files
1. `run_analysis.R`: The main script that reads the raw data, does the transformations, and writes the simplified output to a file
2. `clean_label.R`: A file with a couple of functions that are used to clean up column names
3. `tidy_wearables_summary.R`: The output file generated by the script `run_analysis.R`

The original raw files are not included in this repository. They can be downloaded from primary source. See Instructions below.

## Instructions 
1. Download the files in your working directory
2. Download the zip file from https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip and extract the folder "UC HAR Dataset" into your working directory
3. In your R environment, run the analysis using `source("run_analysis.R")`
4. When the script finishes running, the output will be a file called `tidy_wearables_summary.csv` in your working directory.
5. Data can be interpreted using the attached data dictionary file.
